---
title: "Descritpive analysis"
output: html_document
date: "2023-04-18"
---

This markdown completes the descriptive analysis for the thesis. It summarises the word lengths and uses word clouds to find the most frequently used words of each party. 
```{r}
library(quanteda.textplots)
```

```{r}
c <- read.csv("~/Documents/ASDS/Thesis /BudgetStatementsCleaned.csv") %>%
  select(-c(X))
```


```{r}

# Create corpus 
## Need to add name of person making speech as a docvar?
corp <- corpus(c)

docnames(corp) <- c$speaker
  #c("Gordon Brown 97","Gordon Brown 98", "Gordon Brown 99", "Gordon Brown 00", "Gordon Brown 01", "Gordon Brown 02", "Gordon Brown 03", "Gordon Brown 04", "Gordon Brown 05", "Gordon Brown 06", "Gordon Brown 07", "Alistair Darling 08",  "Alistair Darling 09", "Alistair Darling March 10", "George Osborne 10","George Osborne 11", "George Osborne 12", "George Osborne 13", "George Osborne 14", "George Osborne March 15", "George Osborne July 15", "George Osborne 16","Phillip Hammond March 17","Phillip Hammond Nov 17","Phillip Hammond 18", "Rishi Sunak 20","Rishi Sunak March 21","Rishi Sunak Oct 21", "Jeremy Hunt 22", "Jeremy Hunt 23")

# Clean corpus 
budget_tokens <- tokens(corp, remove_punct = TRUE, remove_numbers = TRUE , remove_symbols = T) %>%
  tokens_remove(c(stopwords("en"), "can", "also", "get", "now", "government", "uk", "make", "already", "means", "next", "us", "mr", "speaker", "deputy", "want", "like", "tax", "year", "per", "cent", "today", "new", "2015-16", "rhf",  "its", "well", "were", "weve", "thats", "march", "cent", "pre-budget", "honourable",  "going", "donâ€™t", "let", ".", "cent", "say", "people", "plan", "today", "largest", "thank", "column", "will", "country", "need", "deliver", "announce", "propose", "promise", "week", "countries", "set", "budget", "billion", "million", "april", "britain", "promis", "invest", "support", "just", "meet", "take", "work", "bn", "economic", "economy", "secretaries", "made", "announcing", "are", "able", "forecast", "united kingdom", "british", "get", "year", "madame", "measure", "done", "take", "fact", "one", "even","making", "many", "still", "without", "know", "course", "way", "much", "almost", "really", "put", "part", "know", "makes", "another", "many", "least", "yet", "back", "getting", "terms", "believe", "long", "good", "must", "look", "continue", "come", "far", "past", "see", "what", "real", "getting", "keep", "enough", "find", "simply", "bill", "place", "last", "around", "actually", "however", "think", "many", "first", "needs", "right", "less", "little", "bring", "thing", "bring", "across", "needed")) %>% 
  tokens_remove(pattern = "\\d{4}-\\d{2}")

budget_tokens <- budget_tokens %>%
  tokens_wordstem()


budget_dfm <- dfm(budget_tokens)


```

Now for the analysis. First begin by looking at frequency of words.
```{r}
# Sum of tokens 
sum(ntoken(budget_dfm))
sum(ntoken(dfm_subset(budget_dfm, party == "Labour")))
sum(ntoken(dfm_subset(budget_dfm, party == "Conservative")))
mean(ntoken(dfm_subset(budget_dfm, party == "Labour")))
mean(ntoken(dfm_subset(budget_dfm, party == "Conservative")))
mean(ntoken(dfm_subset(budget_dfm, yearInGov == 1)))
mean(ntoken(dfm_subset(budget_dfm, yearInGov == 2)))
mean(ntoken(dfm_subset(budget_dfm, yearInGov == 3)))
mean(ntoken(dfm_subset(budget_dfm, yearInGov == 4)))
mean(ntoken(dfm_subset(budget_dfm, yearInGov == 5)))
mean(ntoken(dfm_subset(budget_dfm, yearInGov == 6)))
mean(ntoken(dfm_subset(budget_dfm, yearInGov == 7)))
mean(ntoken(dfm_subset(budget_dfm, yearInGov == 8)))
mean(ntoken(dfm_subset(budget_dfm, yearInGov == 9)))
mean(ntoken(dfm_subset(budget_dfm, yearInGov == 10)))


## Wordclouds of top most 100 frequent words by party. 
textplot_wordcloud(dfm_subset(budget_dfm, party == "Labour"), rotation = 0.25, 
                   color = rev(RColorBrewer::brewer.pal(10, "RdBu")), max_words = 100) 

textplot_wordcloud(dfm_subset(budget_dfm, party == "Conservative"), rotation = 0.25, 
                   color = rev(RColorBrewer::brewer.pal(10, "RdBu")), max_words = 100) 
```

Now look at sentiment of words overall. Just play around with the data to get a greater understanding of it. 
```{r}
mfd0 <- dfm_lookup(dfm_weight(dfm_subset(budget_dfm, party == "Labour"), scheme = "prop"), dictionary = data_dictionary_MFD)

mfd0
moral0 <- as.data.frame(apply(mfd0, 2, mean))

moral0

mfd1 <- dfm_lookup(dfm_weight(dfm_subset(budget_dfm, party == "Conservative"), scheme = "prop"), dictionary = data_dictionary_MFD)

mfd1
moral1 <- as.data.frame(apply(mfd1, 2, mean))

moral1

kwic(tokens(corp), "opportunity", window = 6)
kwic(tokens(corp), "relief", window = 2)
kwic(tokens(corp), "children", window = 2)
kwic(tokens(corp), "benefits", window = 2)
kwic(tokens(corp), "help", window = 2)
kwic(tokens(corp), "support", window = 2)
kwic(tokens(corp), "inequality", window = 2)
kwic(tokens(corp), "housing", window = 2)
kwic(tokens(corp), "elderly", window = 2)
kwic(tokens(corp), "disability", window = 2)
kwic(tokens(corp), "differently abled", window = 2)
kwic(tokens(corp), "homeless", window = 2)
kwic(tokens(corp), "education", window = 2)
kwic(tokens(corp), "unemployed", window = 2)
kwic(tokens(corp), "accessibility", window = 2)
kwic(tokens(corp), "welfare", window = 2)
kwic(tokens(corp), "poverty", window = 2)
kwic(tokens(corp), "reform", window = 15)

# Equaloty dictionary 
equality <- dictionary(list(equality = c("relief", "support", "benefits", "help", "support", "homeless", "education", "welfare", "children", "unemployed", "disability", "discrimination", "just", "diverse", "equality", "fair", "poverty", "wealth", "equity", "access", "inclusion", "wealthy")))

dfm_lookup(budget_dfm, equality, case_insensitive = T)


kwic(tokens(corp, remove_punct = TRUE, remove_numbers = TRUE , remove_symbols = T), equality, window = 2)


budget_subset <- dfm_group(budget_dfm, groups = party)

# Calculate keyness and determine Trump as target group
result_keyness <- textstat_keyness(budget_subset, target = "Labour")

# Plot estimated word keyness
textplot_keyness(result_keyness) 
```


